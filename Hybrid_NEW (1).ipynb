{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For Building recommender systems\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K34bGtp-FXzp",
        "outputId": "6dc55c5b-57be-4add-a4c5-98758f4877dc"
      },
      "execution_count": 620,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 621,
      "metadata": {
        "id": "OtkTr_jngKIr"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import random # For generating random numbers or making random selections\n",
        "import numpy as np # For numerical operations, such as arrays and mathematical functions\n",
        "import pickle # For serializing and deserializing Python objects\n",
        "import pandas as pd # For data manipulation and analysis, especially with DataFrames\n",
        "from surprise import SVD, Dataset, Reader # For building recommendation systems\n",
        "from sklearn.preprocessing import MinMaxScaler # To scale features to a specified range, typically [0, 1]\n",
        "from datetime import datetime, timedelta #For handling date and time operations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv('/content/news.csv')\n",
        "rec_items_df = pd.read_csv('/content/rec_items.csv')\n",
        "rec_feedback_df = pd.read_csv('/content/rec_feedback.csv')\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "rec_users_df = pd.read_csv('/content/rec_users.csv')"
      ],
      "metadata": {
        "id": "mhS1TXJ8gbrB"
      },
      "execution_count": 622,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CBF model (TF-IDF and Cosine Similarity Matrix)\n",
        "tfidf = joblib.load('/content/tfidf_vectorizer.pkl')\n",
        "cosine_sim = joblib.load('/content/cosine_similarity_matrix.pkl')\n",
        "\n",
        "# Load the CF model (e.g., a pre-trained collaborative filtering model)\n",
        "cf_model = joblib.load('/content/svd_recommender_model.pkl')"
      ],
      "metadata": {
        "id": "vSKphCAGFHbh"
      },
      "execution_count": 623,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recent_trending_news(rec_feedback_df, top_n=5, days=7):\n",
        "    \"\"\"Fetch trending articles based on recent engagement (last 'days').\"\"\"\n",
        "\n",
        "    # Check if the 'timestamp' column exists in the DataFrame\n",
        "    if \"timestamp\" not in rec_feedback_df.columns:\n",
        "        print(\"No timestamp column found. Falling back to general trending news.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    # Convert the 'timestamp' column to datetime format. Invalid timestamps are set to NaT (Not a Time)\n",
        "    rec_feedback_df[\"timestamp\"] = pd.to_datetime(rec_feedback_df[\"timestamp\"], errors='coerce')\n",
        "\n",
        "    # Check for invalid timestamps\n",
        "    if rec_feedback_df[\"timestamp\"].isnull().all():\n",
        "        print(\"All timestamps are invalid. Falling back to general trending news.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    # Calculate the date for 'days' ago from the current date\n",
        "    recent_date = datetime.now() - timedelta(days=days)\n",
        "\n",
        "    # Filter the DataFrame to include only rows where the 'timestamp' is within the last 'days' period\n",
        "    recent_engagements = rec_feedback_df[rec_feedback_df[\"timestamp\"] >= recent_date]\n",
        "\n",
        "    if recent_engagements.empty:\n",
        "        print(\"No recent engagements found. Falling back to general trending news.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    # Get the top N most frequent items from the recent engagements\n",
        "    trending = (\n",
        "        recent_engagements[\"item_id\"]\n",
        "        .value_counts()\n",
        "        .head(top_n)\n",
        "        .index.tolist()\n",
        "    )\n",
        "\n",
        "    # Return the trending items if found, otherwise return an empty list\n",
        "    return trending if trending else []"
      ],
      "metadata": {
        "id": "akFcc41LDdSs"
      },
      "execution_count": 624,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to calculate a dynamic \"alpha\" value based on a user's interaction history in rec_feedback_df\n",
        "def calculate_user_alpha(user_id, rec_feedback_df):\n",
        "\n",
        "\n",
        "    # Filters the DataFrame to get all rows where the 'user_id' matches the given user_id, representing all the user's interactions\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "\n",
        "    # Counts the total number of interactions (rows) for that user in the DataFrame\n",
        "    total_interactions = len(user_interactions)\n",
        "\n",
        "    if total_interactions == 0:\n",
        "        return 0.5  # Returns a neutral alpha value (0.5) if no interactions are found\n",
        "\n",
        "    # If the user has interactions, calculates the alpha as the ratio of interactions to 100, constrained between 0 and 1\n",
        "    return min(1, max(0, total_interactions / 100))"
      ],
      "metadata": {
        "id": "fNkItcRFDkZM"
      },
      "execution_count": 625,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_marginal_relevance(recommendations, hybrid_scores, cosine_sim, top_n=5):\n",
        "    selected_items = []\n",
        "    for item in recommendations:\n",
        "        # Penalize items that are too similar to those already selected\n",
        "        similarity_score = sum(cosine_sim.get(item, {}).get(other_item, 0) for other_item in selected_items)\n",
        "        adjusted_score = hybrid_scores[item] - similarity_score * 0.7  # Increase the penalty to 0.7\n",
        "        hybrid_scores[item] = adjusted_score\n",
        "\n",
        "    # Sort by adjusted hybrid score and return the top N items\n",
        "    return sorted(hybrid_scores.keys(), key=lambda x: hybrid_scores[x], reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "8xMFEPVcDn5M"
      },
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to normalize the scores to a range of 0-1 for fair weighting\n",
        "def normalize_scores(scores):\n",
        "\n",
        "    if not scores:\n",
        "        return {} # If there are no scores, returns an empty dictionary\n",
        "\n",
        "    # Converts the values of the 'scores' dictionary to a NumPy array and reshapes it into a column vector (for scaling)\n",
        "    values = np.array(list(scores.values())).reshape(-1, 1)\n",
        "\n",
        "    # Creates an instance of the MinMaxScaler, which scales values to the range [0, 1]\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Fits the scaler to the values and transforms them to the range [0, 1]\n",
        "    normalized_values = scaler.fit_transform(values).flatten()\n",
        "\n",
        "    # Returns a dictionary where each original score is mapped to its normalized value\n",
        "    return {key: norm_score for key, norm_score in zip(scores.keys(), normalized_values)}"
      ],
      "metadata": {
        "id": "w7X2xfv8DqQT"
      },
      "execution_count": 627,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Defines a function to get the top N content-based recommendations using cosine similarity\n",
        "def recommend_content_based(news_id, top_n=5):\n",
        "\n",
        "    # Checks if the given news_id exists in the cosine_sim dictionary\n",
        "    if news_id not in cosine_sim:\n",
        "        return [] # If the news_id is not found, return an empty list\n",
        "\n",
        "    # Creates a list of tuples, where each tuple contains an index (item ID) and its cosine similarity value to the given news_id\n",
        "    similar_items = list(enumerate(cosine_sim[news_id]))\n",
        "\n",
        "    # Sorts the similar items by their cosine similarity value in descending order (most similar first)\n",
        "    sorted_items = sorted(similar_items, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Returns a list of the top N most similar item IDs, based on the sorted cosine similarity values\n",
        "    return [item[0] for item in sorted_items[:top_n]]"
      ],
      "metadata": {
        "id": "jnKm4iufDsHD"
      },
      "execution_count": 628,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to get the top N collaborative filtering recommendations using Singular Value Decomposition (SVD)\n",
        "def recommend_collaborative(user_id, model, rec_feedback_df, top_n=5):\n",
        "\n",
        "     # Checks if the user_id exists in the 'user_id' column of the rec_feedback_df DataFrame\n",
        "    if user_id not in rec_feedback_df['user_id'].values:\n",
        "        return []\n",
        "\n",
        "    # Retrieves all unique item IDs from the 'item_id' column in the rec_feedback_df DataFrame\n",
        "    all_items = rec_feedback_df['item_id'].unique()\n",
        "\n",
        "    # Uses the SVD to predict the user's rating for each item\n",
        "    predictions = {item: model.predict(user_id, item).est for item in all_items}\n",
        "\n",
        "    # Sorts the items based on the predicted rating (est) in descending order (highest predicted rating first)\n",
        "    # Returns the top N items with the highest predictions\n",
        "    return sorted(predictions, key=predictions.get, reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "d7msOVcRDuJj"
      },
      "execution_count": 629,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svd_model = joblib.load('/content/svd_recommender_model.pkl')\n",
        "\n",
        "def recommend_hybrid(user_id, news_id, rec_feedback_df, model=svd_model, top_n=5):\n",
        "    \"\"\"Hybrid recommendation system combining content-based and collaborative filtering.\"\"\"\n",
        "\n",
        "    # Filter the DataFrame for user-specific interactions\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "\n",
        "    # If the user has no interactions, trigger fallback to trending news\n",
        "    if user_interactions.empty:\n",
        "        print(f\"No data for user {user_id}. Showing recent trending news...\")\n",
        "        return get_recent_trending_news(rec_feedback_df, top_n=top_n) or random.sample(list(rec_feedback_df[\"item_id\"].unique()), top_n)\n",
        "\n",
        "    # Calculate dynamic alpha based on the user's interaction history\n",
        "    alpha = calculate_user_alpha(user_id, rec_feedback_df)\n",
        "\n",
        "    # Fetch content-based recommendations (CBF) for the given news_id\n",
        "    cbf_recommendations = recommend_content_based(news_id, top_n=top_n)\n",
        "\n",
        "    # Fetch collaborative filtering recommendations (CF) for the given user\n",
        "    cf_recommendations = recommend_collaborative(user_id, model, rec_feedback_df, top_n=top_n)\n",
        "\n",
        "    # Assign cosine similarity scores for the CBF recommendations\n",
        "    cbf_scores = {item: cosine_sim[news_id][item] for item in cbf_recommendations}\n",
        "\n",
        "    # Assign predicted scores for the CF recommendations\n",
        "    cf_scores = {item: model.predict(user_id, item).est for item in cf_recommendations}\n",
        "\n",
        "    # Normalize both CBF and CF scores to a range of [0, 1]\n",
        "    cbf_scores = normalize_scores(cbf_scores)\n",
        "    cf_scores = normalize_scores(cf_scores)\n",
        "\n",
        "    # Dictionary to store hybrid scores (CBF + CF)\n",
        "    hybrid_scores = {}\n",
        "\n",
        "    # Combine the scores from both filtering approaches using the alpha value\n",
        "    for item in set(cbf_recommendations + cf_recommendations):\n",
        "        cbf_score = cbf_scores.get(item, 0)  # Default to 0 if no CBF score\n",
        "        cf_score = cf_scores.get(item, 0)  # Default to 0 if no CF score\n",
        "        hybrid_scores[item] = alpha * cbf_score + (1 - alpha) * cf_score\n",
        "\n",
        "    # Apply Maximal Marginal Relevance (MMR) to diversify the recommendations\n",
        "    top_recommendations = max_marginal_relevance(list(hybrid_scores.keys()), hybrid_scores, cosine_sim, top_n=top_n)\n",
        "\n",
        "    # If no recommendations were found, trigger fallback to trending news\n",
        "    if not top_recommendations:\n",
        "        print(f\"No recommendations found for user {user_id}. Showing recent trending news...\")\n",
        "        return get_recent_trending_news(rec_feedback_df, top_n=top_n) or random.sample(list(rec_feedback_df[\"item_id\"].unique()), top_n)\n",
        "\n",
        "    # Return the top N hybrid recommendations\n",
        "    return top_recommendations"
      ],
      "metadata": {
        "id": "hwZTk_EIDv1T"
      },
      "execution_count": 631,
      "outputs": []
    }
  ]
}