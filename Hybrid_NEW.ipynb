{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For Building recommender systems\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyV3Qv1jjxzC",
        "outputId": "407c6e58-226e-4c64-e957-24d0dcb69010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtkTr_jngKIr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split, GridSearchCV\n",
        "from surprise import accuracy\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv('/content/news.csv')\n",
        "rec_items_df = pd.read_csv('/content/rec_items.csv')\n",
        "rec_feedback_df = pd.read_csv('/content/rec_feedback.csv')\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "rec_users_df = pd.read_csv('/content/rec_users.csv')"
      ],
      "metadata": {
        "id": "mhS1TXJ8gbrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CBF model (TF-IDF and Cosine Similarity Matrix)\n",
        "tfidf = joblib.load('/content/tfidf_vectorizer.pkl')\n",
        "cosine_sim = joblib.load('/content/cosine_similarity_matrix.pkl')\n",
        "\n",
        "# Load the CF model (e.g., a pre-trained collaborative filtering model)\n",
        "cf_model = joblib.load('/content/svd_recommender_model.pkl')"
      ],
      "metadata": {
        "id": "vSKphCAGFHbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Get Trending News\n",
        "def get_recent_trending_news(rec_feedback_df, top_n=5, days=7):\n",
        "    if \"timestamp\" not in rec_feedback_df.columns:\n",
        "        print(\"No timestamp column found. Using most interacted articles.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    rec_feedback_df[\"timestamp\"] = pd.to_datetime(rec_feedback_df[\"timestamp\"], errors='coerce')\n",
        "\n",
        "    if rec_feedback_df[\"timestamp\"].isnull().all():\n",
        "        print(\"All timestamps are invalid. Using most interacted articles.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    recent_date = datetime.now() - timedelta(days=days)\n",
        "    recent_engagements = rec_feedback_df[rec_feedback_df[\"timestamp\"] >= recent_date]\n",
        "\n",
        "    if recent_engagements.empty:\n",
        "        print(\"No recent engagements found. Using most interacted articles.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    trending = recent_engagements[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "    return trending if trending else []"
      ],
      "metadata": {
        "id": "akFcc41LDdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Calculate User Alpha (Hybrid Weighting)\n",
        "def calculate_user_alpha(user_id, rec_feedback_df):\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "    total_interactions = len(user_interactions)\n",
        "    return min(1, max(0, total_interactions / 100)) if total_interactions else 0.5"
      ],
      "metadata": {
        "id": "fNkItcRFDkZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximal Marginal Relevance (MMR) for Diversity\n",
        "def max_marginal_relevance(recommendations, hybrid_scores, cosine_sim, top_n=5):\n",
        "    selected_items = []\n",
        "    for item in recommendations:\n",
        "        similarity_score = sum(cosine_sim.get(item, {}).get(other_item, 0) for other_item in selected_items)\n",
        "        adjusted_score = hybrid_scores[item] - similarity_score * 0.7\n",
        "        hybrid_scores[item] = adjusted_score\n",
        "    return sorted(hybrid_scores.keys(), key=lambda x: hybrid_scores[x], reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "8xMFEPVcDn5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Scores to [0, 1] Range\n",
        "def normalize_scores(scores):\n",
        "    if not scores:\n",
        "        return {}\n",
        "    values = np.array(list(scores.values())).reshape(-1, 1)\n",
        "    scaler = MinMaxScaler()\n",
        "    normalized_values = scaler.fit_transform(values).flatten()\n",
        "    return {key: norm_score for key, norm_score in zip(scores.keys(), normalized_values)}"
      ],
      "metadata": {
        "id": "w7X2xfv8DqQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Content-Based Recommendation (CBF)\n",
        "def recommend_content_based(news_id, top_n=5):\n",
        "    id_to_index = {news_df['id'][i]: i for i in range(len(news_df))}\n",
        "\n",
        "    if news_id not in id_to_index:\n",
        "        print(f\"News ID {news_id} not found in dataset.\")\n",
        "        return []\n",
        "\n",
        "    index = id_to_index[news_id]\n",
        "    similar_items = list(enumerate(cosine_sim[index]))\n",
        "    sorted_items = sorted(similar_items, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    recommended_items = [news_df['id'][item[0]] for item in sorted_items[1:top_n+1]]\n",
        "    return news_df[news_df['id'].isin(recommended_items)][['id', 'title']]"
      ],
      "metadata": {
        "id": "jnKm4iufDsHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_collaborative(user_id, model, rec_feedback_df, top_n=5):\n",
        "    if user_id not in rec_feedback_df['user_id'].values:\n",
        "        return []\n",
        "    all_items = rec_feedback_df['item_id'].unique()\n",
        "    predictions = {item: model.predict(user_id, item).est for item in all_items}\n",
        "\n",
        "    return sorted(predictions, key=predictions.get, reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "d7msOVcRDuJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_all(user_id, rec_feedback_df, news_df, model=cf_model, top_n=5):\n",
        "    # Check if required columns are present\n",
        "    if 'id' not in news_df.columns:\n",
        "        raise KeyError(\"'id' column not found in news_df\")\n",
        "    if 'item_id' not in rec_feedback_df.columns:\n",
        "        raise KeyError(\"'item_id' column not found in rec_feedback_df\")\n",
        "\n",
        "    # Get user interactions from rec_feedback_df\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "\n",
        "    if user_interactions.empty:\n",
        "        # If no interactions for the user, return trending news\n",
        "        print(f\"No data for user {user_id}. Showing recent trending news...\")\n",
        "        trending_ids = get_recent_trending_news(rec_feedback_df, top_n=top_n) or random.sample(list(rec_feedback_df[\"item_id\"].unique()), top_n)\n",
        "        return {\n",
        "            \"CF\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "            \"CBF\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "            \"Hybrid\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "        }\n",
        "\n",
        "    # Calculate alpha dynamically based on user-specific data (e.g., recency, activity)\n",
        "    alpha = calculate_user_alpha(user_id, rec_feedback_df)\n",
        "\n",
        "    # Get the last interacted item by the user (e.g., the most recent item they interacted with)\n",
        "    last_interacted_news_id = user_interactions.iloc[-1][\"item_id\"]\n",
        "\n",
        "    # Content-based filtering recommendations\n",
        "    cbf_recommendations = recommend_content_based(last_interacted_news_id, top_n=top_n)\n",
        "\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = recommend_collaborative(user_id, model, rec_feedback_df, top_n=top_n)\n",
        "\n",
        "    # Map news id to index for the cosine similarity matrix (used in CBF)\n",
        "    id_to_index = {news_df['id'][i]: i for i in range(len(news_df))}\n",
        "\n",
        "    # Ensure last_interacted_news_id is safely mapped to an index\n",
        "    if last_interacted_news_id not in id_to_index:\n",
        "        print(f\"News ID {last_interacted_news_id} not found in index mapping.\")\n",
        "        last_interacted_index = None\n",
        "    else:\n",
        "        last_interacted_index = id_to_index[last_interacted_news_id]\n",
        "\n",
        "    # Compute CBF Scores safely using cosine similarity matrix\n",
        "    if last_interacted_index is not None:\n",
        "        cbf_scores = {\n",
        "            item: cosine_sim[last_interacted_index][id_to_index[item]]\n",
        "            for item in cbf_recommendations['id'] if item in id_to_index\n",
        "        }\n",
        "    else:\n",
        "        cbf_scores = {}\n",
        "\n",
        "    # CF Scores (Collaborative Filtering)\n",
        "    cf_scores = {item: model.predict(user_id, item).est for item in cf_recommendations}\n",
        "\n",
        "    # Normalize both CBF and CF scores to a range of [0, 1]\n",
        "    cbf_scores = normalize_scores(cbf_scores)\n",
        "    cf_scores = normalize_scores(cf_scores)\n",
        "\n",
        "    # Hybrid scoring (weighted sum of CF and CBF scores)\n",
        "    hybrid_scores = {\n",
        "        item: alpha * cbf_scores.get(item, 0) + (1 - alpha) * cf_scores.get(item, 0)\n",
        "        for item in set(cbf_recommendations['id']).union(cf_recommendations)\n",
        "    }\n",
        "\n",
        "    # Apply Maximal Marginal Relevance (MMR) to diversify the recommendations\n",
        "    top_hybrid_recommendations = max_marginal_relevance(list(hybrid_scores.keys()), hybrid_scores, cosine_sim, top_n=top_n)\n",
        "\n",
        "    return {\n",
        "        \"CF\": news_df[news_df[\"id\"].isin(cf_recommendations)][[\"id\", \"title\"]],\n",
        "        \"CBF\": cbf_recommendations,\n",
        "        \"Hybrid\": news_df[news_df[\"id\"].isin(top_hybrid_recommendations)][[\"id\", \"title\"]],\n",
        "    }"
      ],
      "metadata": {
        "id": "RpLEi-fKWEy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 2329\n",
        "recommendations = recommend_all(user_id, rec_feedback_df, news_df)\n",
        "\n",
        "# Output for CF Recommendations\n",
        "print(f\"\\nTop CF recommendations for User {user_id}:\")\n",
        "print(\"=\"*40)\n",
        "print(recommendations[\"CF\"].to_string(index=False))\n",
        "\n",
        "# Output for CBF Recommendations\n",
        "print(f\"\\nTop CBF recommendations for User {user_id}:\")\n",
        "print(\"=\"*40)\n",
        "print(recommendations[\"CBF\"].to_string(index=False))\n",
        "\n",
        "# Output for Hybrid Recommendations\n",
        "print(f\"\\nTop Hybrid recommendations for User {user_id}:\")\n",
        "print(\"=\"*40)\n",
        "print(recommendations[\"Hybrid\"].to_string(index=False))"
      ],
      "metadata": {
        "id": "4ICuuuzEFRfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa58364d-cf98-471b-da9b-4f835a6faf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top CF recommendations for User 2329:\n",
            "========================================\n",
            "   id                                                                                 title\n",
            "23953                                           අදානි සුලං බලාගාර ව්‍යාපෘතියෙන් ඉවත් වෙයි.?\n",
            "23942                               එක්සත් අරාබි එමීර් රාජ්‍යය හා ශ්‍රී ලංකාව අතර ගිවිසුමක්\n",
            "23941 ජනපති ලෝක නායකයන් ඇමතූ දේශණයේ ‘ඉන්දීය මහද්වීපය හා ආලෝක වර්ෂ ගණනක වේගය’ නිවැරදි කරයි.\n",
            "23937     යුරෝපයට පලා යද්දී මෙරට Ex. මන්ත‍්‍රීවරයෙකු තමින්නාඩු පොලිස් අත්අඩංගුවට. රිමාන්ඩ්.\n",
            "23930                                                  විදුලි කප්පාදුව අදත් - වේලාවන් මෙන්න\n",
            "\n",
            "Top CBF recommendations for User 2329:\n",
            "========================================\n",
            "   id                                                      title\n",
            "23551                 පාස්කු බෝම්බ චෝදනාවට ගෝටාගෙන් ප‍්‍රකාශයක්.\n",
            "23299    ජනපති යාපනයේ – උතුරේ රැකියා විරහිත උපාධිධාරීන් පාරට බහී\n",
            "23285         ජනපති යාපනය කච්චේරිය ඇතුලේ සිටියදී එලියේ විරෝධතා.\n",
            "23063                     බඹර ප්‍රහාරයකින් පාසල් සිසුවෙක් මියයයි\n",
            "23003 නිදහස් උත්සවයේ පෙරහුරු අද සිට - පාසල් කටයුතු ගැනත් තීරණයක්\n",
            "\n",
            "Top Hybrid recommendations for User 2329:\n",
            "========================================\n",
            "   id                                                                             title\n",
            "23937 යුරෝපයට පලා යද්දී මෙරට Ex. මන්ත‍්‍රීවරයෙකු තමින්නාඩු පොලිස් අත්අඩංගුවට. රිමාන්ඩ්.\n",
            "23551                                        පාස්කු බෝම්බ චෝදනාවට ගෝටාගෙන් ප‍්‍රකාශයක්.\n",
            "23299                           ජනපති යාපනයේ – උතුරේ රැකියා විරහිත උපාධිධාරීන් පාරට බහී\n",
            "23285                                ජනපති යාපනය කච්චේරිය ඇතුලේ සිටියදී එලියේ විරෝධතා.\n",
            "23003                        නිදහස් උත්සවයේ පෙරහුරු අද සිට - පාසල් කටයුතු ගැනත් තීරණයක්\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUnique user IDs in the feedback data:\")\n",
        "print(rec_feedback_df['user_id'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NSBqLk9AwkZ",
        "outputId": "82931725-38aa-4d3e-adab-5dcded2eaef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique user IDs in the feedback data:\n",
            "[1182 1058  698 1203 1045 2303 1760  700  695 1221  795 1376  268  482\n",
            "  417  787 1980 1427 1783 1147  797 1362  704 1245  891 1312 2280  678\n",
            " 1490  257  258 1546  777 2329 1144  726 1244 2292 1958 2095  469 1483\n",
            " 1993 2126 1770 2301  650  691  848  645 1984  286 1021  886  980 1093\n",
            " 1814 1375  662 1417  646  714 1798 2163 1356  270  333 1085  876 1477\n",
            " 1755  273 2258 1042  262 2115 1184 1108 1602  930 1200 1540  272 1717\n",
            " 1526  707 1495 2203 1482  737 1979 1192  287 1397  425  349  676 2252\n",
            "  261 2139 1711 1126 2281 1749  979 1349  679]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "def evaluate_model(recommended_items, relevant_items):\n",
        "    # Convert lists to sets for easier comparison\n",
        "    recommended_set = set(recommended_items)\n",
        "    relevant_set = set(relevant_items)\n",
        "\n",
        "    # Precision: How many recommended items were actually relevant\n",
        "    precision = len(recommended_set.intersection(relevant_set)) / len(recommended_set)\n",
        "\n",
        "    # Recall: How many relevant items were recommended\n",
        "    recall = len(recommended_set.intersection(relevant_set)) / len(relevant_set)\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "# Example user recommendations and interactions\n",
        "cf_recommendations = [23565, 16432, 20016, 23603, 23609]  # CF recommended items\n",
        "cbf_recommendations = [23269, 23484, 23848, 23521, 23826]  # CBF recommended items\n",
        "hybrid_recommendations = [23937, 23551, 23299, 23285, 23003]  # Hybrid recommended items\n",
        "\n",
        "# Example relevant items (could be items user actually interacted with or rated positively)\n",
        "relevant_items = [23565, 23484, 23269, 23299, 23003]\n",
        "\n",
        "# Evaluate CF, CBF, Hybrid\n",
        "cf_precision, cf_recall = evaluate_model(cf_recommendations, relevant_items)\n",
        "cbf_precision, cbf_recall = evaluate_model(cbf_recommendations, relevant_items)\n",
        "hybrid_precision, hybrid_recall = evaluate_model(hybrid_recommendations, relevant_items)\n",
        "\n",
        "print(f\"CF Precision: {cf_precision}, CF Recall: {cf_recall}\")\n",
        "print(f\"CBF Precision: {cbf_precision}, CBF Recall: {cbf_recall}\")\n",
        "print(f\"Hybrid Precision: {hybrid_precision}, Hybrid Recall: {hybrid_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACHP9_biYxhO",
        "outputId": "8fbc430d-7855-4c58-f1dc-862124109dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CF Precision: 0.2, CF Recall: 0.2\n",
            "CBF Precision: 0.4, CBF Recall: 0.4\n",
            "Hybrid Precision: 0.4, Hybrid Recall: 0.4\n"
          ]
        }
      ]
    }
  ]
}