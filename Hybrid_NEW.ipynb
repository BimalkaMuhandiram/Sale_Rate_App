{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For Building recommender systems\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K34bGtp-FXzp",
        "outputId": "2cf0aeb9-4d88-48f6-b4d7-2d24d0ea1dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtkTr_jngKIr"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import random # For generating random numbers or making random selections\n",
        "import numpy as np # For numerical operations, such as arrays and mathematical functions\n",
        "import pickle # For serializing and deserializing Python objects\n",
        "import pandas as pd # For data manipulation and analysis, especially with DataFrames\n",
        "from surprise import SVD, Dataset, Reader # For building recommendation systems\n",
        "from sklearn.preprocessing import MinMaxScaler # To scale features to a specified range, typically [0, 1]\n",
        "from datetime import datetime, timedelta #For handling date and time operations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv('/content/news.csv')\n",
        "rec_items_df = pd.read_csv('/content/rec_items.csv')\n",
        "rec_feedback_df = pd.read_csv('/content/rec_feedback.csv')\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "rec_users_df = pd.read_csv('/content/rec_users.csv')"
      ],
      "metadata": {
        "id": "mhS1TXJ8gbrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CBF model (TF-IDF and Cosine Similarity Matrix)\n",
        "tfidf = joblib.load('/content/tfidf_vectorizer.pkl')\n",
        "cosine_sim = joblib.load('/content/cosine_similarity_matrix.pkl')\n",
        "\n",
        "# Load the CF model (e.g., a pre-trained collaborative filtering model)\n",
        "cf_model = joblib.load('/content/svd_recommender_model.pkl')"
      ],
      "metadata": {
        "id": "vSKphCAGFHbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recent_trending_news(rec_feedback_df, top_n=5, days=7):\n",
        "    \"\"\"Fetch trending articles based on recent engagement (last 'days').\"\"\"\n",
        "\n",
        "    # Check if the 'timestamp' column exists in the DataFrame\n",
        "    if \"timestamp\" not in rec_feedback_df.columns:\n",
        "        print(\"No timestamp column found. Falling back to general trending news.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    # Convert the 'timestamp' column to datetime format. Invalid timestamps are set to NaT (Not a Time)\n",
        "    rec_feedback_df[\"timestamp\"] = pd.to_datetime(rec_feedback_df[\"timestamp\"], errors='coerce')\n",
        "\n",
        "    # Check for invalid timestamps\n",
        "    if rec_feedback_df[\"timestamp\"].isnull().all():\n",
        "        print(\"All timestamps are invalid. Falling back to general trending news.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    # Calculate the date for 'days' ago from the current date\n",
        "    recent_date = datetime.now() - timedelta(days=days)\n",
        "\n",
        "    # Filter the DataFrame to include only rows where the 'timestamp' is within the last 'days' period\n",
        "    recent_engagements = rec_feedback_df[rec_feedback_df[\"timestamp\"] >= recent_date]\n",
        "\n",
        "    if recent_engagements.empty:\n",
        "        print(\"No recent engagements found. Falling back to general trending news.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    # Get the top N most frequent items from the recent engagements\n",
        "    trending = (\n",
        "        recent_engagements[\"item_id\"]\n",
        "        .value_counts()\n",
        "        .head(top_n)\n",
        "        .index.tolist()\n",
        "    )\n",
        "\n",
        "    # Return the trending items if found, otherwise return an empty list\n",
        "    return trending if trending else []"
      ],
      "metadata": {
        "id": "akFcc41LDdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to calculate a dynamic \"alpha\" value based on a user's interaction history in rec_feedback_df\n",
        "def calculate_user_alpha(user_id, rec_feedback_df):\n",
        "\n",
        "\n",
        "    # Filters the DataFrame to get all rows where the 'user_id' matches the given user_id, representing all the user's interactions\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "\n",
        "    # Counts the total number of interactions (rows) for that user in the DataFrame\n",
        "    total_interactions = len(user_interactions)\n",
        "\n",
        "    if total_interactions == 0:\n",
        "        return 0.5  # Returns a neutral alpha value (0.5) if no interactions are found\n",
        "\n",
        "    # If the user has interactions, calculates the alpha as the ratio of interactions to 100, constrained between 0 and 1\n",
        "    return min(1, max(0, total_interactions / 100))"
      ],
      "metadata": {
        "id": "fNkItcRFDkZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_marginal_relevance(recommendations, hybrid_scores, cosine_sim, top_n=5):\n",
        "    selected_items = []\n",
        "    for item in recommendations:\n",
        "        # Penalize items that are too similar to those already selected\n",
        "        similarity_score = sum(cosine_sim.get(item, {}).get(other_item, 0) for other_item in selected_items)\n",
        "        adjusted_score = hybrid_scores[item] - similarity_score * 0.7  # Increase the penalty to 0.7\n",
        "        hybrid_scores[item] = adjusted_score\n",
        "\n",
        "    # Sort by adjusted hybrid score and return the top N items\n",
        "    return sorted(hybrid_scores.keys(), key=lambda x: hybrid_scores[x], reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "8xMFEPVcDn5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to normalize the scores to a range of 0-1 for fair weighting\n",
        "def normalize_scores(scores):\n",
        "\n",
        "    if not scores:\n",
        "        return {} # If there are no scores, returns an empty dictionary\n",
        "\n",
        "    # Converts the values of the 'scores' dictionary to a NumPy array and reshapes it into a column vector (for scaling)\n",
        "    values = np.array(list(scores.values())).reshape(-1, 1)\n",
        "\n",
        "    # Creates an instance of the MinMaxScaler, which scales values to the range [0, 1]\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Fits the scaler to the values and transforms them to the range [0, 1]\n",
        "    normalized_values = scaler.fit_transform(values).flatten()\n",
        "\n",
        "    # Returns a dictionary where each original score is mapped to its normalized value\n",
        "    return {key: norm_score for key, norm_score in zip(scores.keys(), normalized_values)}"
      ],
      "metadata": {
        "id": "w7X2xfv8DqQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_content_based(news_id, top_n=5):\n",
        "    # Create a mapping from item_id to index in the cosine similarity matrix\n",
        "    id_to_index = {news_df['id'][i]: i for i in range(len(news_df))}\n",
        "\n",
        "    # Check if news_id exists in the id_to_index mapping\n",
        "    if news_id not in id_to_index:\n",
        "        print(f\"Item ID {news_id} not found in cosine similarity matrix\")\n",
        "        return []\n",
        "\n",
        "    # Get the index of the item_id in the cosine similarity matrix\n",
        "    index = id_to_index[news_id]\n",
        "\n",
        "    # Fetch the cosine similarity values for the given news_id (row from the cosine_sim matrix)\n",
        "    similar_items = list(enumerate(cosine_sim[index]))\n",
        "\n",
        "    # Sort the similar items based on cosine similarity in descending order\n",
        "    sorted_items = sorted(similar_items, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top N similar item IDs (ignoring the first item which is the item itself)\n",
        "    recommended_items = [news_df['id'][item[0]] for item in sorted_items[1:top_n+1]]  # Skip the first item as it's the same as news_id\n",
        "\n",
        "    # Get the titles of the recommended items\n",
        "    recommended_titles = news_df[news_df['id'].isin(recommended_items)][['id', 'title']]\n",
        "\n",
        "    return recommended_titles"
      ],
      "metadata": {
        "id": "jnKm4iufDsHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines a function to get the top N collaborative filtering recommendations using Singular Value Decomposition (SVD)\n",
        "def recommend_collaborative(user_id, model, rec_feedback_df, top_n=5):\n",
        "\n",
        "     # Checks if the user_id exists in the 'user_id' column of the rec_feedback_df DataFrame\n",
        "    if user_id not in rec_feedback_df['user_id'].values:\n",
        "        return []\n",
        "\n",
        "    # Retrieves all unique item IDs from the 'item_id' column in the rec_feedback_df DataFrame\n",
        "    all_items = rec_feedback_df['item_id'].unique()\n",
        "\n",
        "    # Uses the SVD to predict the user's rating for each item\n",
        "    predictions = {item: model.predict(user_id, item).est for item in all_items}\n",
        "\n",
        "    # Sorts the items based on the predicted rating (est) in descending order (highest predicted rating first)\n",
        "    # Returns the top N items with the highest predictions\n",
        "    return sorted(predictions, key=predictions.get, reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "d7msOVcRDuJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_all(user_id, rec_feedback_df, news_df, model=svd_model, top_n=5):\n",
        "    \"\"\"Return CF, CBF, and Hybrid recommendation systems for the user with article titles.\"\"\"\n",
        "\n",
        "    # Ensure column names are correct\n",
        "    if 'id' not in news_df.columns:\n",
        "        raise KeyError(\"'id' column not found in news_df\")\n",
        "    if 'item_id' not in rec_feedback_df.columns:\n",
        "        raise KeyError(\"'item_id' column not found in rec_feedback_df\")\n",
        "\n",
        "    # Filter the DataFrame for user-specific interactions\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "\n",
        "    # If the user has no interactions, trigger fallback to trending news\n",
        "    if user_interactions.empty:\n",
        "        print(f\"No data for user {user_id}. Showing recent trending news...\")\n",
        "        trending_ids = get_recent_trending_news(rec_feedback_df, top_n=top_n) or random.sample(list(rec_feedback_df[\"item_id\"].unique()), top_n)\n",
        "        return {\n",
        "            \"CF\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "            \"CBF\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "            \"Hybrid\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "        }\n",
        "\n",
        "    # Calculate dynamic alpha based on the user's interaction history\n",
        "    alpha = calculate_user_alpha(user_id, rec_feedback_df)\n",
        "\n",
        "    # Fetch content-based recommendations (CBF)\n",
        "    cbf_recommendations = recommend_content_based(user_id, top_n=top_n)\n",
        "\n",
        "    # Fetch collaborative filtering recommendations (CF)\n",
        "    cf_recommendations = recommend_collaborative(user_id, model, rec_feedback_df, top_n=top_n)\n",
        "\n",
        "    # Assign cosine similarity scores for the CBF recommendations\n",
        "    cbf_scores = {item: cosine_sim[user_id][item] for item in cbf_recommendations}\n",
        "\n",
        "    # Assign predicted scores for the CF recommendations\n",
        "    cf_scores = {item: model.predict(user_id, item).est for item in cf_recommendations}\n",
        "\n",
        "    # Normalize both CBF and CF scores to a range of [0, 1]\n",
        "    cbf_scores = normalize_scores(cbf_scores)\n",
        "    cf_scores = normalize_scores(cf_scores)\n",
        "\n",
        "    # Dictionary to store hybrid scores (CBF + CF)\n",
        "    hybrid_scores = {}\n",
        "\n",
        "    # Combine the scores from both filtering approaches using the alpha value\n",
        "    for item in set(cbf_recommendations + cf_recommendations):\n",
        "        cbf_score = cbf_scores.get(item, 0)  # Default to 0 if no CBF score\n",
        "        cf_score = cf_scores.get(item, 0)  # Default to 0 if no CF score\n",
        "        hybrid_scores[item] = alpha * cbf_score + (1 - alpha) * cf_score\n",
        "\n",
        "    # Apply Maximal Marginal Relevance (MMR) to diversify the recommendations\n",
        "    top_hybrid_recommendations = max_marginal_relevance(list(hybrid_scores.keys()), hybrid_scores, cosine_sim, top_n=top_n)\n",
        "\n",
        "    # Get top recommendations for CF, CBF, and Hybrid\n",
        "    top_cbf_recommendations = news_df[news_df[\"id\"].isin(cbf_recommendations)].sort_values(\"id\")[[\"id\", \"title\"]].head(top_n)\n",
        "    top_cf_recommendations = news_df[news_df[\"id\"].isin(cf_recommendations)].sort_values(\"id\")[[\"id\", \"title\"]].head(top_n)\n",
        "    top_hybrid_recommendations = news_df[news_df[\"id\"].isin(top_hybrid_recommendations)].sort_values(\"id\")[[\"id\", \"title\"]].head(top_n)\n",
        "\n",
        "    # Return a dictionary with CF, CBF, and Hybrid recommendations\n",
        "    return {\n",
        "        \"CF\": top_cf_recommendations,\n",
        "        \"CBF\": top_cbf_recommendations,\n",
        "        \"Hybrid\": top_hybrid_recommendations\n",
        "    }"
      ],
      "metadata": {
        "id": "hwZTk_EIDv1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 2329\n",
        "recommendations = recommend_all(user_id, rec_feedback_df, news_df)\n",
        "\n",
        "# Output the recommendations\n",
        "print(f\"Top CF recommendations for User {user_id}:\")\n",
        "print(recommendations[\"CF\"])\n",
        "\n",
        "print(f\"Top CBF recommendations for User {user_id}:\")\n",
        "print(recommendations[\"CBF\"])\n",
        "\n",
        "print(f\"Top Hybrid recommendations for User {user_id}:\")\n",
        "print(recommendations[\"Hybrid\"])"
      ],
      "metadata": {
        "id": "4ICuuuzEFRfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 2329\n",
        "news_id = 23937\n",
        "\n",
        "# Get content-based recommendations\n",
        "cbf_recommendations = recommend_content_based(news_id)\n",
        "\n",
        "# Output the recommendations\n",
        "print(\"Top CBF recommendations:\")\n",
        "print(cbf_recommendations)"
      ],
      "metadata": {
        "id": "QcNJUASbI3M2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}