{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For Building recommender systems\n",
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K34bGtp-FXzp",
        "outputId": "6c8f7c19-4667-4448-8536-0e6adc70090d"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 454,
      "metadata": {
        "id": "OtkTr_jngKIr"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import random # For generating random numbers or making random selections\n",
        "import numpy as np # For numerical operations, such as arrays and mathematical functions\n",
        "import pickle # For serializing and deserializing Python objects\n",
        "import pandas as pd # For data manipulation and analysis, especially with DataFrames\n",
        "from surprise import SVD, Dataset, Reader # For building recommendation systems\n",
        "from sklearn.preprocessing import MinMaxScaler # To scale features to a specified range, typically [0, 1]\n",
        "from datetime import datetime, timedelta #For handling date and time operations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv('/content/news.csv')\n",
        "rec_items_df = pd.read_csv('/content/rec_items.csv')\n",
        "rec_feedback_df = pd.read_csv('/content/rec_feedback.csv')\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "rec_users_df = pd.read_csv('/content/rec_users.csv')"
      ],
      "metadata": {
        "id": "mhS1TXJ8gbrB"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CBF model (TF-IDF and Cosine Similarity Matrix)\n",
        "tfidf = joblib.load('/content/tfidf_vectorizer.pkl')\n",
        "cosine_sim = joblib.load('/content/cosine_similarity_matrix.pkl')\n",
        "\n",
        "# Load the CF model (e.g., a pre-trained collaborative filtering model)\n",
        "cf_model = joblib.load('/content/knn_recommender_model.pkl')"
      ],
      "metadata": {
        "id": "vSKphCAGFHbh"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Get Trending News\n",
        "def get_recent_trending_news(rec_feedback_df, top_n=5, days=7):\n",
        "    if \"timestamp\" not in rec_feedback_df.columns:\n",
        "        print(\"No timestamp column found. Using most interacted articles.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    rec_feedback_df[\"timestamp\"] = pd.to_datetime(rec_feedback_df[\"timestamp\"], errors='coerce')\n",
        "\n",
        "    if rec_feedback_df[\"timestamp\"].isnull().all():\n",
        "        print(\"All timestamps are invalid. Using most interacted articles.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    recent_date = datetime.now() - timedelta(days=days)\n",
        "    recent_engagements = rec_feedback_df[rec_feedback_df[\"timestamp\"] >= recent_date]\n",
        "\n",
        "    if recent_engagements.empty:\n",
        "        print(\"No recent engagements found. Using most interacted articles.\")\n",
        "        return rec_feedback_df[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "\n",
        "    trending = recent_engagements[\"item_id\"].value_counts().head(top_n).index.tolist()\n",
        "    return trending if trending else []"
      ],
      "metadata": {
        "id": "akFcc41LDdSs"
      },
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Calculate User Alpha (Hybrid Weighting)\n",
        "def calculate_user_alpha(user_id, rec_feedback_df):\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "    total_interactions = len(user_interactions)\n",
        "    return min(1, max(0, total_interactions / 100)) if total_interactions else 0.5"
      ],
      "metadata": {
        "id": "fNkItcRFDkZM"
      },
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximal Marginal Relevance (MMR) for Diversity\n",
        "def max_marginal_relevance(recommendations, hybrid_scores, cosine_sim, top_n=5):\n",
        "    selected_items = []\n",
        "    for item in recommendations:\n",
        "        similarity_score = sum(cosine_sim.get(item, {}).get(other_item, 0) for other_item in selected_items)\n",
        "        adjusted_score = hybrid_scores[item] - similarity_score * 0.7\n",
        "        hybrid_scores[item] = adjusted_score\n",
        "    return sorted(hybrid_scores.keys(), key=lambda x: hybrid_scores[x], reverse=True)[:top_n]"
      ],
      "metadata": {
        "id": "8xMFEPVcDn5M"
      },
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Scores to [0, 1] Range\n",
        "def normalize_scores(scores):\n",
        "    if not scores:\n",
        "        return {}\n",
        "    values = np.array(list(scores.values())).reshape(-1, 1)\n",
        "    scaler = MinMaxScaler()\n",
        "    normalized_values = scaler.fit_transform(values).flatten()\n",
        "    return {key: norm_score for key, norm_score in zip(scores.keys(), normalized_values)}"
      ],
      "metadata": {
        "id": "w7X2xfv8DqQT"
      },
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Content-Based Recommendation (CBF) using pre-trained cosine similarity\n",
        "def recommend_content_based(news_id, news_df, top_n=5):\n",
        "    # Create a mapping of news_id to index for quick lookup\n",
        "    id_to_index = {news_df['id'][i]: i for i in range(len(news_df))}\n",
        "\n",
        "    # Ensure the provided news_id exists in the dataset\n",
        "    if news_id not in id_to_index:\n",
        "        print(f\"News ID {news_id} not found in dataset.\")\n",
        "        return []\n",
        "\n",
        "    # Get the index for the last interacted news\n",
        "    index = id_to_index[news_id]\n",
        "\n",
        "    # Fetch the similarity scores for the last interacted item\n",
        "    similar_items = list(enumerate(cosine_sim[index]))\n",
        "\n",
        "    # Sort items based on similarity score in descending order\n",
        "    sorted_items = sorted(similar_items, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top N similar items (excluding the item itself)\n",
        "    recommended_items = [news_df['id'][item[0]] for item in sorted_items[1:top_n+1]]\n",
        "\n",
        "    return news_df[news_df['id'].isin(recommended_items)][['id', 'title']]"
      ],
      "metadata": {
        "id": "jnKm4iufDsHD"
      },
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_collaborative(user_id, model, rec_feedback_df, top_n=5):\n",
        "    # Get all items that the user has not interacted with yet\n",
        "    all_items = rec_feedback_df['item_id'].unique()\n",
        "    interacted_items = rec_feedback_df[rec_feedback_df['user_id'] == user_id]['item_id'].unique()\n",
        "    items_to_predict = list(set(all_items) - set(interacted_items))\n",
        "\n",
        "    # Get CF scores for the items\n",
        "    predictions = {}\n",
        "    for item in items_to_predict:\n",
        "        predictions[item] = model.predict(user_id, item).est\n",
        "\n",
        "    # Log the predictions for debugging\n",
        "    print(f\"CF predictions for user {user_id}: {predictions}\")\n",
        "\n",
        "    # Sort predictions and return top N\n",
        "    recommended_items = sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    return [item[0] for item in recommended_items]"
      ],
      "metadata": {
        "id": "d7msOVcRDuJj"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_all(user_id, rec_feedback_df, news_df, model=cf_model, top_n=5):\n",
        "    if 'id' not in news_df.columns:\n",
        "        raise KeyError(\"'id' column not found in news_df\")\n",
        "    if 'item_id' not in rec_feedback_df.columns:\n",
        "        raise KeyError(\"'item_id' column not found in rec_feedback_df\")\n",
        "\n",
        "    user_interactions = rec_feedback_df[rec_feedback_df[\"user_id\"] == user_id]\n",
        "\n",
        "    if user_interactions.empty:\n",
        "        print(f\"No data for user {user_id}. Showing recent trending news...\")\n",
        "        trending_ids = get_recent_trending_news(rec_feedback_df, top_n=top_n) or random.sample(list(rec_feedback_df[\"item_id\"].unique()), top_n)\n",
        "        return {\n",
        "            \"CF\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "            \"CBF\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "            \"Hybrid\": news_df[news_df[\"id\"].isin(trending_ids)][[\"id\", \"title\"]],\n",
        "        }\n",
        "\n",
        "    alpha = calculate_user_alpha(user_id, rec_feedback_df)\n",
        "    last_interacted_news_id = user_interactions.iloc[-1][\"item_id\"]\n",
        "\n",
        "    # Content-based filtering recommendations using pre-trained cosine similarity\n",
        "    cbf_recommendations = recommend_content_based(last_interacted_news_id, news_df, top_n=top_n)\n",
        "\n",
        "    # Collaborative filtering recommendations\n",
        "    cf_recommendations = recommend_collaborative(user_id, model, rec_feedback_df, top_n=top_n)\n",
        "\n",
        "    # Debugging: Check the structure of the recommendations\n",
        "    print(\"CBF Recommendations:\", cbf_recommendations)\n",
        "    print(\"CF Recommendations:\", cf_recommendations)\n",
        "\n",
        "    # Check if cbf_recommendations is a list of IDs or dictionaries\n",
        "    if isinstance(cbf_recommendations, list):\n",
        "        # If it's a list of IDs\n",
        "        cbf_ids = cbf_recommendations\n",
        "    elif isinstance(cbf_recommendations, list) and isinstance(cbf_recommendations[0], dict) and 'id' in cbf_recommendations[0]:\n",
        "        # If it's a list of dictionaries\n",
        "        cbf_ids = [rec['id'] for rec in cbf_recommendations]\n",
        "    else:\n",
        "        # If neither, print an error and handle accordingly\n",
        "        print(\"Unexpected format for CBF recommendations\")\n",
        "        cbf_ids = []\n",
        "\n",
        "    # Check if cf_recommendations is a list of IDs or dictionaries\n",
        "    if isinstance(cf_recommendations, list):\n",
        "        # If it's a list of IDs\n",
        "        cf_ids = cf_recommendations\n",
        "    elif isinstance(cf_recommendations, list) and isinstance(cf_recommendations[0], dict) and 'id' in cf_recommendations[0]:\n",
        "        # If it's a list of dictionaries\n",
        "        cf_ids = [rec['id'] for rec in cf_recommendations]\n",
        "    else:\n",
        "        # If neither, print an error and handle accordingly\n",
        "        print(\"Unexpected format for CF recommendations\")\n",
        "        cf_ids = []\n",
        "\n",
        "    # Now we combine both CF and CBF recommendations into the hybrid list\n",
        "    hybrid_recommendations = list(set(cbf_ids).union(cf_ids))\n",
        "\n",
        "    # Create a mapping from news_id to index in the cosine similarity matrix\n",
        "    id_to_index = {news_df['id'].iloc[i]: i for i in range(len(news_df))}\n",
        "\n",
        "    # Ensure last_interacted_news_id is mapped to an index safely\n",
        "    if last_interacted_news_id not in id_to_index:\n",
        "        print(f\"News ID {last_interacted_news_id} not found in index mapping.\")\n",
        "        last_interacted_index = None\n",
        "    else:\n",
        "        last_interacted_index = id_to_index[last_interacted_news_id]\n",
        "\n",
        "    # Compute CBF Scores safely\n",
        "    if last_interacted_index is not None:\n",
        "        cbf_scores = {\n",
        "            item: cosine_sim[last_interacted_index][id_to_index[item]]\n",
        "            for item in cbf_ids if item in id_to_index\n",
        "        }\n",
        "    else:\n",
        "        cbf_scores = {}\n",
        "\n",
        "    # Collaborative filtering scores\n",
        "    cf_scores = {item: model.predict(user_id, item).est for item in cf_ids}\n",
        "\n",
        "    # Normalize both CBF and CF scores to a range of [0, 1]\n",
        "    cbf_scores = normalize_scores(cbf_scores)\n",
        "    cf_scores = normalize_scores(cf_scores)\n",
        "\n",
        "    # Hybrid scoring: Combine CF and CBF scores\n",
        "    hybrid_scores = {item: alpha * cbf_scores.get(item, 0) + (1 - alpha) * cf_scores.get(item, 0) for item in hybrid_recommendations}\n",
        "\n",
        "    # Apply Maximal Marginal Relevance (MMR) to diversify the recommendations\n",
        "    top_hybrid_recommendations = max_marginal_relevance(list(hybrid_scores.keys()), hybrid_scores, cosine_sim, top_n=top_n)\n",
        "\n",
        "    # Return recommendations\n",
        "    return {\n",
        "        \"CF\": news_df[news_df[\"id\"].isin(cf_ids)][[\"id\", \"title\"]],\n",
        "        \"CBF\": news_df[news_df[\"id\"].isin(cbf_ids)][[\"id\", \"title\"]],\n",
        "        \"Hybrid\": news_df[news_df[\"id\"].isin(top_hybrid_recommendations)][[\"id\", \"title\"]],\n",
        "    }"
      ],
      "metadata": {
        "id": "RpLEi-fKWEy5"
      },
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 2329\n",
        "recommendations = recommend_all(user_id, rec_feedback_df, news_df)\n",
        "\n",
        "# Output for CF Recommendations\n",
        "print(f\"\\nTop CF recommendations for User {user_id}:\")\n",
        "print(\"=\"*40)\n",
        "print(recommendations[\"CF\"].to_string(index=False))\n",
        "\n",
        "# Output for CBF Recommendations\n",
        "print(f\"\\nTop CBF recommendations for User {user_id}:\")\n",
        "print(\"=\"*40)\n",
        "print(recommendations[\"CBF\"].to_string(index=False))\n",
        "\n",
        "# Output for Hybrid Recommendations\n",
        "print(f\"\\nTop Hybrid recommendations for User {user_id}:\")\n",
        "print(\"=\"*40)\n",
        "print(recommendations[\"Hybrid\"].to_string(index=False))"
      ],
      "metadata": {
        "id": "4ICuuuzEFRfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98cb4c2-fd5a-4ee1-ade2-36b46f97eeb1"
      },
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CF predictions for user 2329: {23565: 1, 16432: 1, 20016: 1, 23603: 1, 23609: 1, 22090: 1, 23118: 1, 22612: 1, 23639: 1, 22618: 1, 18530: 1, 23140: 1, 23652: 1, 23653: 1, 17513: 1, 22307: 1, 23149: 1, 23150: 1, 23662: 1, 23664: 1, 22641: 1, 17521: 1, 23666: 1, 23668: 1, 23679: 1, 16519: 1, 23689: 1, 23692: 1, 23693: 1, 23695: 1, 17557: 1, 23702: 1, 23708: 1, 23711: 1, 23712: 1, 23713: 1, 23715: 1, 23718: 1, 18599: 1, 23721: 1, 23722: 1, 23723: 1, 23732: 1, 23733: 1, 23735: 1, 17596: 1, 23740: 1, 23742: 1, 23232: 1, 23744: 1, 23745: 1, 23747: 1, 17604: 1, 23749: 1, 23750: 1, 23239: 1, 23240: 1, 21705: 1, 23754: 1, 23753: 1, 23756: 1, 22733: 1, 23759: 1, 23760: 1, 23761: 1, 23763: 1, 23764: 1, 23254: 1, 22743: 1, 23766: 1, 23767: 1, 23769: 1, 23770: 1, 23771: 1, 23774: 1, 23778: 1, 23780: 1, 23781: 1, 23782: 1, 23783: 1, 23786: 1, 23275: 1, 16620: 1, 23788: 1, 23789: 1, 23791: 1, 23794: 1, 23795: 1, 23796: 1, 23797: 1, 23799: 1, 23800: 1, 23801: 1, 23804: 1, 23293: 1, 19709: 1, 23805: 1, 23806: 1, 23808: 1, 23810: 1, 21762: 1, 23813: 1, 21766: 1, 23303: 1, 23816: 1, 23819: 1, 23820: 1, 23309: 1, 16657: 1, 23314: 1, 23832: 1, 22298: 1, 23836: 1, 23837: 1, 23326: 1, 23838: 1, 23328: 1, 17184: 1, 22818: 1, 23840: 1, 23332: 1, 23841: 1, 23842: 1, 23843: 1, 23845: 1, 23847: 1, 23848: 1, 23339: 1, 23340: 1, 23846: 1, 23861: 1, 23863: 1, 23864: 1, 23865: 1, 23867: 1, 23869: 1, 23871: 1, 22338: 1, 23876: 1, 23365: 1, 23877: 1, 23878: 1, 23879: 1, 23880: 1, 23881: 1, 23371: 1, 23882: 1, 19277: 1, 23373: 1, 23883: 1, 23884: 1, 23377: 1, 23885: 1, 23886: 1, 23380: 1, 23381: 1, 23887: 1, 23888: 1, 23889: 1, 23890: 1, 23891: 1, 23892: 1, 23893: 1, 23894: 1, 23895: 1, 23896: 1, 23897: 1, 23898: 1, 23899: 1, 23900: 1, 23903: 1, 23397: 1, 23904: 1, 23906: 1, 23908: 1, 23408: 1, 23920: 1, 23922: 1, 23924: 1, 22901: 1, 23414: 1, 23925: 1, 22904: 1, 23927: 1, 23930: 1, 23933: 1, 23934: 1, 22362: 1, 23936: 1, 22913: 1, 23937: 1, 23427: 1, 23938: 1, 23939: 1, 23940: 1, 23941: 1, 23942: 1, 23433: 1, 23946: 1, 23949: 1, 23952: 1, 23953: 1, 22930: 1, 23442: 1, 23956: 1, 23959: 1, 23962: 1, 21914: 1, 22947: 1, 23462: 1, 22955: 1, 23469: 1, 23471: 1, 22960: 1, 22963: 1, 23475: 1, 23477: 1, 21939: 1, 21941: 1, 22456: 1, 23487: 1, 22976: 1, 23493: 1, 23495: 1, 22988: 1, 20437: 1, 23513: 1, 17373: 1, 22493: 1, 23520: 1, 21995: 1, 23532: 1}\n",
            "CBF Recommendations:         id                                              title\n",
            "439  23551         පාස්කු බෝම්බ චෝදනාවට ගෝටාගෙන් ප‍්‍රකාශයක්.\n",
            "689  23299  ජනපති යාපනයේ – උතුරේ රැකියා විරහිත උපාධිධාරීන්...\n",
            "703  23285  ජනපති යාපනය කච්චේරිය ඇතුලේ සිටියදී එලියේ විරෝ...\n",
            "918  23063             බඹර ප්‍රහාරයකින් පාසල් සිසුවෙක් මියයයි\n",
            "975  23003  නිදහස් උත්සවයේ පෙරහුරු අද සිට - පාසල් කටයුතු ග...\n",
            "CF Recommendations: [23565, 16432, 20016, 23603, 23609]\n",
            "Unexpected format for CBF recommendations\n",
            "\n",
            "Top CF recommendations for User 2329:\n",
            "========================================\n",
            "   id                                                                                             title\n",
            "23609                                                                               කොටස් වෙළෙඳපොළ ඉහළට\n",
            "23603 ඕස්ට්‍රෙලියාවේ 'නාසි සැලියුට්' ගැහුවත් වරදක් - පාර්ලිමේන්තුව යුදෙව් විරෝධයට දැඩි නීති සම්මත කරගනී\n",
            "23565                                                 ඩයනා ගමගේ අත්අඩංගුවට ගන්නැයි වරෙන්තු නිකුත් කරයි.\n",
            "\n",
            "Top CBF recommendations for User 2329:\n",
            "========================================\n",
            "Empty DataFrame\n",
            "Columns: [id, title]\n",
            "Index: []\n",
            "\n",
            "Top Hybrid recommendations for User 2329:\n",
            "========================================\n",
            "   id                                                                                             title\n",
            "23609                                                                               කොටස් වෙළෙඳපොළ ඉහළට\n",
            "23603 ඕස්ට්‍රෙලියාවේ 'නාසි සැලියුට්' ගැහුවත් වරදක් - පාර්ලිමේන්තුව යුදෙව් විරෝධයට දැඩි නීති සම්මත කරගනී\n",
            "23565                                                 ඩයනා ගමගේ අත්අඩංගුවට ගන්නැයි වරෙන්තු නිකුත් කරයි.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUnique user IDs in the feedback data:\")\n",
        "print(rec_feedback_df['user_id'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NSBqLk9AwkZ",
        "outputId": "72fc1259-95a7-4b4d-d668-5eb283fe599e"
      },
      "execution_count": 465,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique user IDs in the feedback data:\n",
            "[1182 1058  698 1203 1045 2303 1760  700  695 1221  795 1376  268  482\n",
            "  417  787 1980 1427 1783 1147  797 1362  704 1245  891 1312 2280  678\n",
            " 1490  257  258 1546  777 2329 1144  726 1244 2292 1958 2095  469 1483\n",
            " 1993 2126 1770 2301  650  691  848  645 1984  286 1021  886  980 1093\n",
            " 1814 1375  662 1417  646  714 1798 2163 1356  270  333 1085  876 1477\n",
            " 1755  273 2258 1042  262 2115 1184 1108 1602  930 1200 1540  272 1717\n",
            " 1526  707 1495 2203 1482  737 1979 1192  287 1397  425  349  676 2252\n",
            "  261 2139 1711 1126 2281 1749  979 1349  679]\n"
          ]
        }
      ]
    }
  ]
}